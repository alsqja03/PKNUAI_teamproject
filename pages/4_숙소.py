import streamlit as st
import requests
import urllib.parse
from openai import OpenAI
import folium
from streamlit_folium import st_folium

# ğŸ” API í‚¤ ì„¤ì •
OPENAI_API_KEY = "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"  # ì—¬ê¸°ì— ë³¸ì¸ì˜ OpenAI API í‚¤ ì…ë ¥
KAKAO_API_KEY = "KakaoAK b3759742989e0c923c37d8baf058f95c"  # ì—¬ê¸°ì— ë³¸ì¸ì˜ Kakao REST API í‚¤ ì…ë ¥

# OpenAI í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key=OPENAI_API_KEY)

# ğŸ§  GPTë¡œ ìˆ™ì†Œ ì¶”ì²œ ë°›ê¸°
def generate_gpt_based_recommendations(area_name):
    prompt = f"""
í•œêµ­ì˜ {area_name} ì§€ì—­ì—ì„œ ì‹¤ì œ ì¡´ì¬í•  ë²•í•œ ìˆ™ì†Œ(ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤, ë¦¬ì¡°íŠ¸ ë“±)ë¥¼ 3~4ê³³ ì¶”ì²œí•´ ì£¼ì„¸ìš”.
ìˆ™ì†Œëª…, ìœ„ì¹˜, ë¶„ìœ„ê¸°, ì¶”ì²œ ì´ìœ ë¥¼ í•¨ê»˜ ì¨ ì£¼ì„¸ìš”.
ê° ìˆ™ì†ŒëŠ” ë§ˆì¹˜ ì—¬í–‰ ë¸”ë¡œê·¸ì—ì„œ ì†Œê°œí•˜ë“¯, ì¤„ ë‚˜ëˆ ì„œ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
- ì‹¤ì œ í•œêµ­ ì—¬í–‰ í”Œë«í¼(ë„¤ì´ë²„ ì§€ë„, ì•¼ë†€ì, ì—¬ê¸°ì–´ë•Œ ë“±)ì—ì„œ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì‹¤ì œ ìˆ™ì†Œëª…ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.
- ë°˜ë“œì‹œ ì „ì²´ ì´ë¦„ì„ í¬í•¨í•˜ê³ , ì§€ì—­ëª…ë„ ì •í™•íˆ ëª…ì‹œí•´ ì£¼ì„¸ìš”.
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì—¬í–‰ ìˆ™ì†Œ ì „ë¬¸ê°€ì•¼."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"âŒ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {e}")
        return "ì¶”ì²œ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ğŸ“ ìˆ™ì†Œëª…ìœ¼ë¡œ ì¢Œí‘œ ê²€ìƒ‰ (ì¹´ì¹´ì˜¤ API)
def get_location_and_image(place_name, region=None):
    query = f"{region} {place_name}" if region else place_name
    headers = {"Authorization": KAKAO_API_KEY}
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    params = {"query": query}
    try:
        res = requests.get(url, headers=headers, params=params).json()
        documents = res.get("documents", [])
        if not documents:
            st.warning(f"ğŸ“ ì¹´ì¹´ì˜¤ ê²€ìƒ‰ ì‹¤íŒ¨: {query}")
            return None, None, None
        top = documents[0]
        name = top["place_name"]
        lat = float(top["y"])
        lon = float(top["x"])
        return name, lat, lon
    except Exception as e:
        st.error(f"âŒ ì¢Œí‘œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None, None, None

# ğŸ—ºï¸ ì§€ë„ì— ë§ˆì»¤ í‘œì‹œ
def show_map_with_places(place_list, region):
    m = folium.Map(location=[36.5, 127.5], zoom_start=6)
    added = False
    for place in place_list:
        name, lat, lon = get_location_and_image(place, region=region)
        if lat and lon:
            folium.Marker(
                location=[lat, lon],
                popup=name,
                icon=folium.Icon(color='blue')
            ).add_to(m)
            added = True
        else:
            st.info(f"âŒ ë§ˆì»¤ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {place}")
    if added:
        st.subheader("ğŸ—ºï¸ ì§€ë„ì—ì„œ ë³´ê¸°")
        st_folium(m, width=700)
    else:
        st.warning("ì§€ë„ì— í‘œì‹œí•  ìˆ™ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")

# â–¶ï¸ Streamlit UI ì‹œì‘
st.set_page_config(page_title="ìˆ™ì†Œ ì¶”ì²œê¸°", page_icon="ğŸ¨")
st.title("ğŸ¨ GPT ê¸°ë°˜ ìˆ™ì†Œ ì¶”ì²œê¸° + ì§€ë„")
st.markdown("ì¢Œì¸¡ ë©”ë‰´ ë˜ëŠ” ë©”ì¸ í™”ë©´ì—ì„œ ì…ë ¥í•œ ì—¬í–‰ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ™ì†Œë¥¼ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤.")

# ğŸ“¥ ë©”ì¸ í˜ì´ì§€ì—ì„œ ì „ë‹¬ëœ ì§€ì—­ëª… ë°›ê¸°
if "location" in st.session_state:
    area_name = st.session_state["location"]
    st.success(f"ì…ë ¥ëœ ì—¬í–‰ì§€: {area_name}")

    with st.spinner("âœï¸ GPTê°€ ìˆ™ì†Œë¥¼ ì¶”ì²œí•˜ëŠ” ì¤‘..."):
        recommendations = generate_gpt_based_recommendations(area_name)

    st.subheader("ğŸ“Œ GPT ì¶”ì²œ ìˆ™ì†Œ ë¦¬ìŠ¤íŠ¸")
    st.markdown(recommendations, unsafe_allow_html=True)

    # ìˆ™ì†Œëª… ì¶”ì¶œ
    stay_names = []
    for line in recommendations.split('\n'):
        if line.strip().startswith(tuple(str(i) + '.' for i in range(1, 10))):
            try:
                name = line.split('.')[1].split('(')[0].strip()
                stay_names.append(name)
            except:
                continue

    st.write("ğŸ¯ ì¶”ì¶œëœ ìˆ™ì†Œëª… ë¦¬ìŠ¤íŠ¸:", stay_names)

    if stay_names:
        st.subheader("ğŸ¨ ìˆ™ì†Œ ì¹´ë“œ ë³´ê¸° + ê²€ìƒ‰ ë§í¬")
        for stay in stay_names:
            query = urllib.parse.quote(stay)
            search_url = f"https://search.naver.com/search.naver?query={query}"
            image_url = f"https://via.placeholder.com/300x200?text={urllib.parse.quote(stay)}"

            card_html = f"""
            <div style="border:1px solid #ccc; border-radius:10px; padding:16px; margin-bottom:20px; box-shadow:2px 2px 8px rgba(0,0,0,0.1);">
                <h4 style="margin-bottom:10px;">ğŸ¨ {stay}</h4>
                <img src="{image_url}" style="width:100%; border-radius:8px; margin-bottom:10px;">
                <a href="{search_url}" target="_blank" style="
                    display:inline-block;
                    padding:8px 16px;
                    background-color:#4CAF50;
                    color:white;
                    text-decoration:none;
                    border-radius:5px;
                    font-weight:bold;
                ">ğŸ” ë„¤ì´ë²„ì—ì„œ ê²€ìƒ‰í•˜ê¸°</a>
            </div>
            """
            st.markdown(card_html, unsafe_allow_html=True)

        show_map_with_places(stay_names, region=area_name)
    else:
        st.warning("â— ìˆ™ì†Œ ì´ë¦„ì„ ì¸ì‹í•  ìˆ˜ ì—†ì–´ ì§€ë„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("ì—¬í–‰ì§€ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”. ë©”ì¸ í™”ë©´ì—ì„œ ì…ë ¥í•˜ë©´ ì—¬ê¸°ì— ìë™ìœ¼ë¡œ ì—°ê²°ë©ë‹ˆë‹¤.")
